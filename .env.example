# ============================================
# ARK-CV Environment Configuration
# ============================================
# Copy this file to .env and add your API keys

# ============================================
# DATABASE CONFIGURATION (Pre-configured)
# ============================================
# Read-only access to pre-populated knowledge base
# These credentials are provided for convenience
DATABASE_URL=REMOVED #Please contact the repository owner for access details.

# Neo4j Knowledge Graph (Read-only)
NEO4J_URI=REMOVED #Please contact the repository owner for access details.
NEO4J_USER=neo4j
NEO4J_PASSWORD=REMOVED #Please contact the repository owner for access details.

# ============================================
# LLM PROVIDER CONFIGURATION
# ============================================
# Choose your preferred LLM provider
# Options: openai, ollama, openrouter, gemini

LLM_PROVIDER=openai

# LLM Base URL
# OpenAI: https://api.openai.com/v1
# Ollama: http://localhost:11434/v1
# OpenRouter: https://openrouter.ai/api/v1
# Gemini: https://generativelanguage.googleapis.com/v1beta
LLM_BASE_URL=https://api.openai.com/v1

# LLM API Key - ADD YOUR KEY HERE
# Get OpenAI key: https://platform.openai.com/api-keys
# Get OpenRouter key: https://openrouter.ai/keys
# Ollama: use "ollama"
# Get Gemini key: https://ai.google.dev/
LLM_API_KEY=sk-your-api-key-here

# LLM Model Choice
# OpenAI examples: gpt-4o-mini, gpt-4o, gpt-4-turbo
# OpenRouter examples: anthropic/claude-3-5-sonnet, meta-llama/llama-3.3-70b-instruct
# Ollama examples: qwen2.5:14b-instruct, llama3:8b
# Gemini examples: gemini-2.0-flash, gemini-1.5-pro
LLM_CHOICE=gpt-4o-mini

# ============================================
# VISION LANGUAGE MODEL (VLM) CONFIGURATION
# ============================================
# For image analysis in Gradio UI
# Must be a model that supports vision/image inputs

# VLM Base URL (can be same as LLM or different)
# OpenAI: https://api.openai.com/v1
# Ollama: http://localhost:11434/v1
VLM_BASE_URL=https://api.openai.com/v1

# VLM API Key - ADD YOUR KEY HERE
# Can be the same as LLM_API_KEY if using same provider
VLM_API_KEY=sk-your-api-key-here

# VLM Model - Must support vision
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-4-vision-preview
# Ollama examples: minicpm-v, llava:13b
VLM_MODEL=gpt-4o

# ============================================
# EMBEDDING MODEL CONFIGURATION
# ============================================
# For vector search in the knowledge base

EMBEDDING_PROVIDER=ollama

# Embedding Base URL
# OpenAI: https://api.openai.com/v1
# Ollama: http://localhost:11434/v1
EMBEDDING_BASE_URL=http://localhost:11434/v1

# Embedding API Key - ADD YOUR KEY HERE
# Use same key as LLM if using OpenAI
# Use "ollama" for local Ollama
EMBEDDING_API_KEY=ollama

# Embedding Model
# OpenAI examples: text-embedding-3-small, text-embedding-3-large
# Ollama examples: nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=nomic-embed-text

# ============================================
# INGESTION CONFIGURATION (Optional)
# ============================================
# Only needed if you plan to add more papers to knowledge base
# Can use a faster/cheaper model for document processing

# Leave empty to use same as LLM_CHOICE
INGESTION_LLM_CHOICE=

# Chunking settings (optimised for knowledge graph)
CHUNK_SIZE=800
CHUNK_OVERLAP=100
MAX_CHUNK_SIZE=1500

# ============================================
# APPLICATION CONFIGURATION
# ============================================
APP_ENV=development
LOG_LEVEL=INFO
APP_HOST=0.0.0.0
APP_PORT=8058

# ============================================
# VECTOR SEARCH CONFIGURATION
# ============================================
VECTOR_DIMENSION=1536
MAX_SEARCH_RESULTS=10

# ============================================
# SESSION CONFIGURATION
# ============================================
SESSION_TIMEOUT_MINUTES=60
MAX_MESSAGES_PER_SESSION=100

# ============================================
# RATE LIMITING
# ============================================
RATE_LIMIT_REQUESTS=60
RATE_LIMIT_WINDOW_SECONDS=60

# ============================================
# DEBUG CONFIGURATION
# ============================================
DEBUG_MODE=false
ENABLE_PROFILING=false
